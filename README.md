# RAG-Agent.-MEPHI-Hack
RAG Агент поиска статей и работы с ними

## **Техническое задание на разработку MVP Документ-агента**

### **1. Telegram Bot (`tg-bot-service`)**

**Цель:** Предоставить пользовательский интерфейс в Telegram. Бот является "тонким клиентом" и делегирует всю логику серверу агента.

**Что нужно сделать:**

1.  **Создать бота:**
    *   Зарегистрировать бота через `@BotFather`, получить токен.
    *   Использовать библиотеку `python-telegram-bot` (async).
2.  **Управление сессиями:**
    *   Генерировать **Session ID** для каждого пользователя. Формат: `tg_{user_id}_{timestamp}`.
    *   Передавать этот `session_id` во все запросы к бэкенду в заголовке `X-Session-Id`.
    *   Сессия не сбрасывается в боте. Бот просто передает ID, а логику времени жизни обрабатывает бэкенд.
3.  **Обработка сообщений:**
    *   На любое текстовое сообщение пользователя (кроме команд) бот должен:
        *   Показать статус "печатает" (`sendChatAction`).
        *   Отправить **POST** запрос на `{AGENT_SERVICE_URL}/invoke`.
        *   Заголовки: `X-Session-Id: <session_id>`, `Content-Type: application/json`.
        *   Тело запроса: `{"query": "текст сообщения пользователя"}`.
        *   Полученный ответ (текст) отдать пользователю как новое сообщение.
4.  **Команды:**
    *   `/start` — Приветственное сообщение, объяснение возможностей.
    *   `/new` — Явный сброс сессии для пользователя. Бот генерирует новый `session_id` и сообщает об этом.
5.  **Обработка ошибок:**
    *   При недоступности бэкенда или ошибке 5xx/4xx отправлять понятное сообщение пользователю ("Сервис временно недоступен, попробуйте позже").
6.  **Развертывание:**
    *   Написать `Dockerfile`.
    *   Конфигурация через переменные окружения: `TELEGRAM_TOKEN`, `AGENT_SERVICE_URL`.

---

### **2. Сервис Агента (`agent-service`) - (Объединенный API Gateway + Core Agent)**

**Цель:** Обрабатывать запросы от бота, управлять диалоговым состоянием (сессией), выполнять логику ReAct и интегрироваться с RAG.

**Что нужно сделать:**

1.  **API Endpoints (FastAPI):**
    *   `POST /invoke`
        *   **Вход:** Заголовок `X-Session-Id`, тело `{"query": "string"}`.
        *   **Логика:**
            1.  **Получение состояния:** По `session_id` получить текущее состояние агента из кэша (см. ниже). Если состояния нет — создать новое (пустой список history).
            2.  **Вызов логики агента:** Передать `query` и `state` (историю) в `ReAct Engine`.
            3.  **Сохранение состояния:** Обновленное состояние (с добавленным новым взаимодействием) сохранить обратно в кэш. **Установить/обновить TTL (Time-To-Live) для ключа session_id на 10 минут**.
            4.  **Ответ:** Вернуть клиенту (боту) финальный ответ агента в формате `{"response": "текст с ответом и цитатами"}`.
    *   `POST /rag/search` (внутренний, но публичный для сервиса)
        *   **Вход:** Тело `{"index": "название_коллекции", "query": "строка запроса", "limit": 5}`.
        *   **Логика:** Вызвать клиент Qdrant и вернуть результаты.
        *   **Ответ:** `{"results": [{"id": "...", "text": "кусок текста", "metadata": {"source": "file.pdf", "page": 1}, "score": 0.95}, ...]}`.
2.  **Модуль состояний (State Manager):**
    *   Реализовать key-value хранилище для состояния сессии.
    *   **Для MVP:** Использовать `Redis` с сериализацией JSON.
    *   **Ключ:** `session:<session_id>` (например, `session:tg_12345_...`).
    *   **Значение (схема):**
        ```json
        {
          "history": [
            {"role": "user", "content": "Что такое ML?"},
            {"role": "assistant", "content": "ML, или машинное обучение, это...", "sources": [...], "used_tools": [...]}
          ],
          "created_at": "2023-...",
          "updated_at": "2023-..."
        }
        ```
    *   Реализовать автоматическое удаление ключей через 10 минут без активности (TTL).
3.  **ReAct Engine (Core Agent):**
    *   Использовать библиотеку `langchain` или `llama-index` для каркаса агента.
    *   Реализовать агента с `ReAct` подходом (Мысли -> Действие -> Наблюдение).
    *   **Инструменты (Tools), которые должен уметь вызывать агент:**
        *   `retrieve_documents(query: str) -> List[Document]`: Внутренне вызывает `/rag/search`. Агент использует его, когда для ответа нужны факты из базы знаний.
        *   `final_answer(answer: str, sources: List[str]) -> str`: Финализирует ответ. Сигнализирует, что цепочка рассуждений завершена.
    *   **Системный промпт:** Четко задать роль: "Ты — помощник, отвечающий на вопросы по документам. Ты ДОЛЖЕН использовать инструмент `retrieve_documents` для поиска информации, если вопрос касается документов. В конце ответа укажи источники в формате [1], [2]..."
    *   Агент должен работать с историей диалога из `state`.
4.  **Интеграция с RAG:**
    *   Реализовать клиент для вызова внутреннего эндпоинта `/rag/search`.
5.  **Развертывание:**
    *   Написать `Dockerfile`.
    *   Конфигурация через переменные окружения: `REDIS_URL`, `QDRANT_URL`, `QDRANT_API_KEY`, `LLM_API_KEY` (OpenAI/другая), `LLM_BASE_URL`.

---

### **3. RAG Core (`qdrant-db` + индекс) + Эмбеддер**

**Цель:** Обеспечить семантический поиск по документам.

**Что нужно сделать:**

1.  **Развернуть Qdrant:**
    *   Использовать официальный образ `qdrant/qdrant`.
    *   Настроить persistence (том для данных).
    *   Для MVP достаточно одного инстанса.
2.  **Создать коллекцию:**
    *   Название: `documents` (или параметризуемое).
    *   Размерность векторов: Должна соответствовать выбранной модели эмбеддингов (например, 768 для `all-MiniLM-L6-v2`, 1536 для `text-embedding-ada-002`).
    *   Тип расстояния: `Cosine`.
    *   Создать payload индексы для полей `source`, `page` (если нужно) для фильтрации.
3.  **Подготовка пайплайна индексации (отдельный скрипт/notebook):**
    *   Принимает папку с документами (PDF, DOCX, TXT).
    *   Разбивает текст на чанки (например, по 512 символов с перекрытием).
    *   Генерирует эмбеддинги для каждого чанка с помощью выбранной модели (для MVP можно `sentence-transformers/all-MiniLM-L6-v2`).
    *   Загружает чанки с эмбеддингами и метаданными (`{"text": "...", "source": "file.pdf", "page": N, "chunk_id": ...}`) в коллекцию Qdrant.
4.  **Сервис эмбеддингов (опционально, для продакшна):**
    *   Для MVP можно запускать модель эмбеддингов прямо в `agent-service`. Для масштабирования позже можно вынести в отдельный микросервис (`embedding-service`), который `agent-service` будет вызывать для векторизации запроса пользователя.
5.  **Развертывание:**
    *   `docker-compose` для локального запуска Qdrant.
    *   Для облака — использовать managed-сервис или k8s deployment.

---

### **Общие требования ко всем компонентам:**

*   **Логирование:** Структурированные логи (JSON) с `session_id`, `request_id` для трассировки.
*   **Конфигурация:** Только через переменные окружения.
*   **Обработка ошибок:** Graceful degradation. Ни один компонент не должен "падать" из-за ошибки в другом. Возвращаются понятные коды и сообщения.
*   **Документация:** Написать краткий `README.md` для каждого сервиса с инструкцией по запуску и примером `.env` файла.
*   **Коммуникация:** Все межсервисные коммуникации по HTTP/REST с JSON. Использовать асинхронные клиенты где возможно.
*   **Безопасность:**
    *   `agent-service` должен проверять наличие/формат `session_id`.
    *   Эндпоинты, кроме `/invoke`, не должны быть публично доступны в prod (использовать firewall, private network).

### **Стек технологий:**
*   **Бот:** `python-telegram-bot` или любая другая удобная библиотека
*   **Сервис Агента:** `FastAPI`/`Sanic`, `langchain`/`llama-index`, `redis-py`, `qdrant-client`, `openai` (или другой LLM клиент)
*   **Кэш:** `Redis`
*   **Векторная БД:** `Qdrant`
*   **Эмбеддинги:** `gigachat-embedder`
*   **LLM:** `GigaChat-Max`
*   **Оркестрация:** `docker-compose` для локальной разработки и первого деплоя.
